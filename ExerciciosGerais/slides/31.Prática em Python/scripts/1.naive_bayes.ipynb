{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formação Cientista de Dados - Fernando Amaral e Jones Granatyr\n",
    "# Algoritmo Naïve Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importação das bibliotecas\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from yellowbrick.classifier import ConfusionMatrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregamento da base de dados e definição dos previsores (variáveis independentes - X) e a classe (variável dependente - y)\n",
    "credito = pd.read_csv('Credit.csv')\n",
    "credito.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credito.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formato de matriz\n",
    "previsores = credito.iloc[:,0:20].values\n",
    "classe = credito.iloc[:,20].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformação dos atributos categóricos em atributos numéricos, passando o índice de cada coluna categórica\n",
    "# Precisamos criar um objeto para cada atributo categórico, pois na sequência vamos executar o processo de encoding novamente para o registro de teste\n",
    "# Se forem utilizados objetos diferentes, o número atribuído a cada valor poderá ser diferente, o que deixará o teste inconsistente\n",
    "labelencoder1 = LabelEncoder()\n",
    "previsores[:,0] = labelencoder1.fit_transform(previsores[:,0])\n",
    "\n",
    "labelencoder2 = LabelEncoder()\n",
    "previsores[:,2] = labelencoder2.fit_transform(previsores[:,2])\n",
    "\n",
    "labelencoder3 = LabelEncoder()\n",
    "previsores[:, 3] = labelencoder3.fit_transform(previsores[:, 3])\n",
    "\n",
    "labelencoder4 = LabelEncoder()\n",
    "previsores[:, 5] = labelencoder4.fit_transform(previsores[:, 5])\n",
    "\n",
    "labelencoder5 = LabelEncoder()\n",
    "previsores[:, 6] = labelencoder5.fit_transform(previsores[:, 6])\n",
    "\n",
    "labelencoder6 = LabelEncoder()\n",
    "previsores[:, 8] = labelencoder6.fit_transform(previsores[:, 8])\n",
    "\n",
    "labelencoder7 = LabelEncoder()\n",
    "previsores[:, 9] = labelencoder7.fit_transform(previsores[:, 9])\n",
    "\n",
    "labelencoder8 = LabelEncoder()\n",
    "previsores[:, 11] = labelencoder8.fit_transform(previsores[:, 11])\n",
    "\n",
    "labelencoder9 = LabelEncoder()\n",
    "previsores[:, 13] = labelencoder9.fit_transform(previsores[:, 13])\n",
    "\n",
    "labelencoder10 = LabelEncoder()\n",
    "previsores[:, 14] = labelencoder10.fit_transform(previsores[:, 14])\n",
    "\n",
    "labelencoder11 = LabelEncoder()\n",
    "previsores[:, 16] = labelencoder11.fit_transform(previsores[:, 16])\n",
    "\n",
    "labelencoder12 = LabelEncoder()\n",
    "previsores[:, 18] = labelencoder12.fit_transform(previsores[:, 18])\n",
    "\n",
    "labelencoder13 = LabelEncoder()\n",
    "previsores[:, 19] = labelencoder13.fit_transform(previsores[:, 19])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divisão da base de dados entre treinamento e teste (30% para testar e 70% para treinar)\n",
    "X_treinamento, X_teste, y_treinamento, y_teste = train_test_split(previsores,\n",
    "                                                                  classe,\n",
    "                                                                  test_size = 0.3,\n",
    "                                                                  random_state = 0)\n",
    "X_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação e treinamento do modelo (geração da tabela de probabilidades)\n",
    "naive_bayes = GaussianNB()\n",
    "naive_bayes.fit(X_treinamento, y_treinamento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previsões utilizando os registros de teste\n",
    "previsoes = naive_bayes.predict(X_teste)\n",
    "previsoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#geração da matriz de confusão e cálculo da taxa de acerto e erro\n",
    "confusao = confusion_matrix(y_teste, previsoes)\n",
    "confusao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxa_acerto = accuracy_score(y_teste, previsoes)\n",
    "taxa_erro = 1 - taxa_acerto\n",
    "taxa_acerto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualização da matriz de confusão\n",
    "# Warning interno da biblioteca yellowbrick, já esta na última versão (sem solução para o warning no momento)\n",
    "v = ConfusionMatrix(GaussianNB())\n",
    "v.fit(X_treinamento, y_treinamento)\n",
    "v.score(X_teste, y_teste)\n",
    "v.poof()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previsão com novo registro, transformando os atributos categóricos em numéricos\n",
    "novo_credito = pd.read_csv('NovoCredit.csv')\n",
    "novo_credito.shape\n",
    "#novo_credito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usamos o mesmo objeto que foi criado antes, para manter o padrão dos dados\n",
    "# Chamamos somente o método \"transform\", pois a adaptação aos dados (fit) já foi feita anteriormente\n",
    "novo_credito = novo_credito.iloc[:,0:20].values\n",
    "novo_credito[:,0] = labelencoder1.transform(novo_credito[:,0])\n",
    "novo_credito[:, 2] = labelencoder2.transform(novo_credito[:, 2])\n",
    "novo_credito[:, 3] = labelencoder3.transform(novo_credito[:, 3])\n",
    "novo_credito[:, 5] = labelencoder4.transform(novo_credito[:, 5])\n",
    "novo_credito[:, 6] = labelencoder5.transform(novo_credito[:, 6])\n",
    "novo_credito[:, 8] = labelencoder6.transform(novo_credito[:, 8])\n",
    "novo_credito[:, 9] = labelencoder7.transform(novo_credito[:, 9])\n",
    "novo_credito[:, 11] = labelencoder8.transform(novo_credito[:, 11])\n",
    "novo_credito[:, 13] = labelencoder9.transform(novo_credito[:, 13])\n",
    "novo_credito[:, 14] = labelencoder10.transform(novo_credito[:, 14])\n",
    "novo_credito[:, 16] = labelencoder11.transform(novo_credito[:, 16])\n",
    "novo_credito[:, 18] = labelencoder12.transform(novo_credito[:, 18])\n",
    "novo_credito[:, 19] = labelencoder13.transform(novo_credito[:, 19])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Resultado da previsão\n",
    "naive_bayes.predict(novo_credito)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
